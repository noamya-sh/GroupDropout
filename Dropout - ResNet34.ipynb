{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyOzTIaekPUzBehl5vvYRT3k"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "premium"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
   ],
   "metadata": {
    "id": "bbiBXgWcPVqc"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Data - CiFAR10**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "O0fRsXUlTTK2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])"
   ],
   "metadata": {
    "id": "C-cSidC7TNqi"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())"
   ],
   "metadata": {
    "id": "ja8NuFgUTNtv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681580781551,
     "user_tz": -180,
     "elapsed": 17368,
     "user": {
      "displayName": "Moriya Bitton",
      "userId": "01730897552901915848"
     }
    },
    "outputId": "62fd13d8-2fb9-48f0-9237-00e689f72617"
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ],
   "metadata": {
    "id": "tOA5AWZiTNwg"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "id": "7HvZwrJePWW0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681580781552,
     "user_tz": -180,
     "elapsed": 36,
     "user": {
      "displayName": "Moriya Bitton",
      "userId": "01730897552901915848"
     }
    },
    "outputId": "07118cfc-7272-42ee-f8ab-382f89c6d4d9"
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Model**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "Ssv9OpeSTrPF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def weights_init(module):\n",
    "  if isinstance(module, nn.Linear):\n",
    "    random_seed = 1\n",
    "    torch.manual_seed(random_seed)\n",
    "    nn.init.normal_(module.weight, mean=0, std=1.0)\n",
    "    \n",
    "    if module.bias is not None:\n",
    "      nn.init.constant_(module.bias, 0) "
   ],
   "metadata": {
    "id": "xU8ZEzZ1EAGa"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample):\n",
    "        super().__init__()\n",
    "        if downsample:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, input):\n",
    "        shortcut = self.shortcut(input)\n",
    "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
    "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
    "        input = input + shortcut\n",
    "        return nn.ReLU()(input)"
   ],
   "metadata": {
    "id": "PsKLvvaMhD4E"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    :parameter\n",
    "    p: probability to drop. Bigger p -> Drop more\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_labels, p=1.0):\n",
    "        super(CustomDropout, self).__init__()\n",
    "        self.p = p\n",
    "        self.num_of_labels = num_of_labels\n",
    "\n",
    "    def forward(self, batch_input, batch_labels):\n",
    "        if self.training:\n",
    "            layer_size = batch_input.size(1)\n",
    "            batch_size = batch_input.size(0)\n",
    "            portion_size = int(layer_size // self.num_of_labels)\n",
    "            # print(f\"portion_size: {portion_size}\")\n",
    "            # print(batch_input)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                label = batch_labels[i].item()\n",
    "                # print(f\"{label} * {portion_size} = {label * portion_size}\")\n",
    "                # print(f\"{label+1} * {portion_size} = {(label + 1) * portion_size}\")\n",
    "                mask = torch.bernoulli(torch.ones_like(batch_input[i]) * (1 - self.p))\n",
    "                # mask = torch.zeros_like()\n",
    "                # print(label * portion_size, \"-\", (label + 1) * portion_size)\n",
    "                # print((1.0 + (1/portion_size)))\n",
    "                mask[label * portion_size : (label + 1) * portion_size] = 1.0 #self.num_of_labels  # give each neuron power of the dropped neurons\n",
    "                batch_input[i] = batch_input[i] * mask\n",
    "\n",
    "            output = batch_input\n",
    "        else:\n",
    "            output = batch_input\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **ResNet**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "misrssGbpDai"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, resblock, repeat, outputs=1000, DROPOUT=True):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        filters = [64, 64, 128, 256, 512]\n",
    "\n",
    "        self.layer1 = nn.Sequential()\n",
    "        self.layer1.add_module('conv2_1', resblock(filters[0], filters[1], downsample=False))\n",
    "        for i in range(1, repeat[0]):\n",
    "                self.layer1.add_module('conv2_%d'%(i+1,), resblock(filters[1], filters[1], downsample=False))\n",
    "\n",
    "        self.layer2 = nn.Sequential()\n",
    "        self.layer2.add_module('conv3_1', resblock(filters[1], filters[2], downsample=True))\n",
    "        for i in range(1, repeat[1]):\n",
    "                self.layer2.add_module('conv3_%d' % (i+1,), resblock(filters[2], filters[2], downsample=False))\n",
    "\n",
    "        self.layer3 = nn.Sequential()\n",
    "        self.layer3.add_module('conv4_1', resblock(filters[2], filters[3], downsample=True))\n",
    "        for i in range(1, repeat[2]):\n",
    "            self.layer3.add_module('conv2_%d' % (i+1,), resblock(filters[3], filters[3], downsample=False))\n",
    "\n",
    "        self.layer4 = nn.Sequential()\n",
    "        self.layer4.add_module('conv5_1', resblock(filters[3], filters[4], downsample=True))\n",
    "        for i in range(1, repeat[3]):\n",
    "            self.layer4.add_module('conv3_%d'%(i+1,), resblock(filters[4], filters[4], downsample=False))\n",
    "\n",
    "        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(filters[4], outputs)\n",
    "        self.dropout = CustomDropout(num_of_labels=10, p=0.5) if DROPOUT else None\n",
    "        if DROPOUT:\n",
    "            print(self.dropout)\n",
    "        # self.dropout = nn.Dropout(p=0.5) if DROPOUT else None\n",
    "\n",
    "    def forward(self, input, input_labels):\n",
    "        input = self.layer0(input)\n",
    "        input = self.layer1(input)\n",
    "        input = self.layer2(input)\n",
    "        input = self.layer3(input)\n",
    "        input = self.layer4(input)\n",
    "        input = self.gap(input)\n",
    "        input = torch.flatten(input, start_dim=1)\n",
    "        input = self.fc(input)\n",
    "        if self.dropout is not None:\n",
    "            input = self.dropout(input, input_labels)\n",
    "\n",
    "        return input"
   ],
   "metadata": {
    "id": "1tau2zWXpHc5"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Train & Test**"
   ],
   "metadata": {
    "id": "OsPUbgOPiapy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# define everything we need for training\n",
    "\n",
    "epochs = 100 #1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "# lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
   ],
   "metadata": {
    "id": "a8MotdABhUs-"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# count trainable parameters of the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "id": "rlxQaNC2Nc-z"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=50, is_inception=False):\n",
    "    \n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'test']: # Each epoch has a training and validation phase\n",
    "            if phase == 'train':\n",
    "                model.train()           # Set model to training mode\n",
    "            else:\n",
    "                model.eval()            # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]: # Iterate over data\n",
    "                \n",
    "                inputs = transforms.functional.resize(inputs, (112, 112))\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # Zero the parameter gradients\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n",
    "                    outputs = model(inputs, labels)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train': # Backward + optimize only if in training phase\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                print(loss.item())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            if phase == 'test': # Adjust learning rate based on val loss\n",
    "                lr_scheduler.step(epoch_loss)\n",
    "                \n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{}\\t Loss: {:.4f}\\t Acc: {:.4f}%'.format(phase, epoch_loss, epoch_acc*100))\n",
    "            \n",
    "            if phase == 'test':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "                # deep copy the model\n",
    "                if epoch_acc > best_acc:\n",
    "                  best_acc = epoch_acc\n",
    "                  # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:4f}%'.format(best_acc*100))\n",
    "\n",
    "    # # load best model weights\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, val_acc_history"
   ],
   "metadata": {
    "id": "xTrfEt5LhZrM"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Train & Test Models**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "j9m2mOwJnmNf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **ResNet34 - Group Dropout**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# resnet34 - dropout\n",
    "res34_d = ResNet(3, ResBlock, [3, 4, 6, 3], outputs=1000, DROPOUT=True)\n",
    "res34_d.apply(weights_init)\n",
    "res34_d.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDropout()\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (layer0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): ReLU()\n  )\n  (layer1): Sequential(\n    (conv2_1): ResBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv2_2): ResBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv2_3): ResBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (conv3_1): ResBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (shortcut): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv3_2): ResBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv3_3): ResBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv3_4): ResBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (conv4_1): ResBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (shortcut): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv2_2): ResBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv2_3): ResBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv2_4): ResBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv2_5): ResBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv2_6): ResBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (conv5_1): ResBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv3_2): ResBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv3_3): ResBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (shortcut): Sequential()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (gap): AdaptiveAvgPool2d(output_size=1)\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n  (dropout): CustomDropout()\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(res34_d) # 21,806,184"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(res34_d.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "res34_d, _ = train_model(res34_d,\n",
    "                         {\"train\": train_loader, \"test\": test_loader},\n",
    "                         criterion,\n",
    "                         optimizer,\n",
    "                         epochs)"
   ],
   "metadata": {
    "id": "xKCTrvuqKHCC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681595565438,
     "user_tz": -180,
     "elapsed": 3597820,
     "user": {
      "displayName": "Moriya Bitton",
      "userId": "01730897552901915848"
     }
    },
    "outputId": "8c113a64-fda0-436a-d1d7-1070dbf0dcb0",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.865478515625\n",
      "92.10539245605469\n",
      "66.04986572265625\n",
      "58.3069953918457\n",
      "52.94820785522461\n",
      "37.41429901123047\n",
      "42.38365173339844\n",
      "39.15611267089844\n",
      "44.498355865478516\n",
      "30.18720245361328\n",
      "35.27131271362305\n",
      "24.94654083251953\n",
      "27.680124282836914\n",
      "21.88913345336914\n",
      "19.67936134338379\n",
      "17.713895797729492\n",
      "23.779987335205078\n",
      "11.991691589355469\n",
      "25.427087783813477\n",
      "21.119979858398438\n",
      "16.383203506469727\n",
      "19.78763198852539\n",
      "21.80624771118164\n",
      "17.806995391845703\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "bVoOfzx4UMun"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}